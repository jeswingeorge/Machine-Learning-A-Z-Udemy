{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\auc_roc_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC curve is used to visualize the performance of a binary classifier that is, the classifier with 2 possible outcomes. \n",
    "- ROC curves takes into consideration all possible thresholds and the threshold determination is done by the business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Link to the ROC setup used in lecture](http://www.navan.name/roc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](images\\roc1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume every blue and red pixel represents a paper for which we want to predict the admission status.\n",
    "\n",
    "![](images\\roc2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume this is a validation dataset and we used logistic regression as it has probabilities also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\roc3.PNG)\n",
    "\n",
    "Lets estimate that height at probability 0.1 is 10 pixels. The aboe plot tells us that there were 10 papers for which we predicted admission probability of 0.1 and true status for all 10 papers was negative i.e, not admitted. \n",
    "\n",
    "> blue - Not admitted  \n",
    "> Red  - Admitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 50 papers for which we predicted admittance probability of 0.3 and none of them were admitted (Pic-1). There were about 20 papers for which we predicted admittance proability of 0.5 but 10 were admitted and 10 (hald) were not admitted (Pic - 2). There were 50 papers for which we predicted a probability of admittance of 70% and all of them were selected (Pic - 3).\n",
    "\n",
    "![](images\\roc4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "\n",
    "![](images\\roc5.PNG)\n",
    "\n",
    "Most of the classifiers have a threshold of 50%.\n",
    "\n",
    "Accuracy rate = %ge of correct predictions\n",
    "\n",
    "At this threshold, more than 90% of the observations are classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Now if our classifier did not do well with thresold of 0.5 and the blue distribution tends more towards the right. Then our classification accuracy will be much lower than before irrespective of the thresold we choose.\n",
    "\n",
    "+ve - Admitted\n",
    "\n",
    "-ve - Not admitted\n",
    "\n",
    "***\n",
    "\n",
    "Now lets discuss ROC curve:\n",
    "\n",
    "##### True positive rate TPR - When the actual classifcation is +ve how often does the classifer predict positive. (Recall)\n",
    "$$ TPR = \\frac{TPs}{all-positives}  = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "##### False positive rate FPR - When the actual classifcation is -ve how often does the classifer predict negative.\n",
    "$$ FPR = \\frac{TNs}{all-negatives}  = \\frac{FP}{FP + TN} $$\n",
    "\n",
    "\n",
    "Both TPR and FPR range from 0 to 1.\n",
    "\n",
    "# ROC curve\n",
    "It is a plot of the TPR  on the y-axis and FPR on the x-axis for every possible classifcation threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example - \n",
    "\n",
    "Setting up a classification threshold of 0.8 such that this threshold will classify 50 papers as admitted and 450 as not admitted.\n",
    "\n",
    "![](images\\roc6.PNG)\n",
    "\n",
    "The TPR will be red pixels to the right of the line divided by all red pixels, i.e.,\n",
    "\n",
    "$$ TPR = \\frac{50}{250} = 0.2 $$\n",
    "\n",
    "The FPR will be blue pixel to the right of the line divided by all blue pixels, i.e.,\n",
    "\n",
    "$$ FPR = \\frac{0}{250} = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we will plot a point on the ROC curve. Plot on ROC curve:\n",
    "\n",
    "$$ (x,y) = (0,0.2) $$ \n",
    "\n",
    "![](images\\roc7.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we move the threshold to 0.5:\n",
    "\n",
    "![](images\\roc8.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we got two points above. But to generate the ROC curve we need to generate TPR and FPR for all possible classifcaton thresholds which range from 0 to 1. Observe how the point on ROC curve moves when we chnage the threshold (refer video - 7:23)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC curve visualizes all possible threshold.\n",
    "- Misclassification rate is error rate for single threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the threshold such that classifcation is good\n",
    "\n",
    "![](images\\roc9.PNG)\n",
    "\n",
    "Therefore a classifier which does a very good job of seperating the classes will have a ROC curve that hugs the upper left corner of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A poor classifier\n",
    "\n",
    "![](images\\roc10.PNG)\n",
    "\n",
    "A poor classifer will have its ROC curve close to the diagonal and it can be equated to random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "Now to quantify the performance of the quantifier - we will use AUC - Area under the curve.\n",
    "\n",
    "![](images\\roc11.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This example is not represesntative of real world problems\n",
    "\n",
    "1. The example we have used here is of a perfectly balanced class that is why the size of blue and red distribution are identical. But most of the real world problems do not have a balanced class.\n",
    "\n",
    "Ex - if only 10% papers were admitted then the blue distribution will be 9 times larger than the red distribution, however that does not change the way ROC curve is generated.\n",
    "\n",
    "2. Predicted probabilities output by classifers are unlikely to follow a particular shape or distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember\n",
    "\n",
    "1. ROC curves and AUC are useful even if your __predicted probabilities__ are not properly calibrated.  \n",
    "   i.e., ROC curve and AUC will be identical even if your predicted probabilities range from 0.9 to 1 instead of 0 to 1 as long as ordering of observations by predictive probabilities remain the same. All the AUC metric cares about is how well your classifier seperates the two classes.\n",
    "   \n",
    "   AUC is only sensitive to rank ordering. We can think of AUC as representing the probability that a classifer will rank a randomly choosen positive observation higher than a randomly choosen negative observation. So  AUC is a useful metric even when your classes are highly imbalanced.  \n",
    "   \n",
    " \n",
    "2. ROC curves can be extended to problems with __3 or more classes__ using a __1 vs all approach__. So if we have 3 classes then we will need to create 3 ROC curves:\n",
    "\n",
    "```\n",
    "Curve 1 -> class 1 (+ve class) vs class 2 and 3 (-ve class)\n",
    "Curve 2 -> class 2 (+ve class) vs class 1 and 3 (-ve class)\n",
    "Curve 3 -> class 3 (+ve class) vs class 1 and 2 (-ve class)\n",
    "```\n",
    "\n",
    "3. Choosing a classiifcation threshold is a business decision: minimize FPR or maximize TPR. (In our journal admittance example it was not obvious what to choose). \n",
    "\n",
    "    Eg: Credit card transaction was fraudulent or not - Business decision might be set the threshold very low which will result in a lot of FPs (false +ves)\n",
    "    ![](images\\roc12.PNG)\n",
    "    \n",
    "    But this will be considered acceptable as that will maximize the TPRs and hence minimize the casein which real instance of fraud was not flagged for review.\n",
    "    ![](images\\roc13.PNG)\n",
    "    \n",
    "    \n",
    "    In the end we always have to choose the classifcation threshold and ROC curve will visually help us understand the imapct of that choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
