{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [Difference between `model.predict()` and `model.predict_proba()`](https://discuss.analyticsvidhya.com/t/what-is-the-difference-between-predict-and-predict-proba/67376/9)\n",
    "\n",
    "Consider a binary classification for labels 0 and 1.\n",
    "\n",
    "__Predict__ will give either 0 or 1 as output  \n",
    "__Predict_proba__ will give the only probability of 1.\n",
    "\n",
    "__predict_proba__ on 2-class classfication problem. Its giving a list of 2 outputs for each observation(row) as below.  predict_proba gives  the probabilities for the target (0 and 1 in this case) in array form. The number of probabilities for each row is equal to the number of categories in target variable (2 in this case).\n",
    "Eg: [0.23780654318010663, 0.7621934568198934]  \n",
    "\n",
    "Yes, here 0.237… is the probability that the output will be 0 and 0.762… is the probability of output being 1.\n",
    "\n",
    "Suppose you only want the probability of getting the output either as 0 or 1, you can do some changes in your code and you will get only one output for each observation. You can use the following code:\n",
    "\n",
    "`model.predict_proba(test)[:,1]`  \n",
    "\n",
    "Here,\n",
    "model is the trained model   \n",
    "Using [:,1] in the code will give you the probabilities of getting the output as 1. If you replace 1 with 0 in the above code, you will only get the probabilities of getting the output as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [ROC](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py)\n",
    "\n",
    "ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.\n",
    "\n",
    "The “steepness” of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.\n",
    "\n",
    "ROC curves are typically used in binary classification to study the output of a classifier. In order to extend ROC curve and ROC area to multi-label classification, it is necessary to binarize the output. \n",
    "\n",
    "##### [Receiver Operating Characteristic (ROC) with cross validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py)\n",
    "\n",
    "### [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)\n",
    "\n",
    "Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from __prediction scores__. Observe the 2nd parameter in the `roc_auc_score(y, clf.predict_proba(X)[:, 1])` is probability scores and not the predicted class 0 or 1. If we use `clf.predict(X)` there we will get wrong value as roc_auc_score.\n",
    "\n",
    "```\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
    "roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "0.99...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.[Comparing different models using ROC-AUC curve](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_roc_curve_visualization_api.html#roc-curve-with-visualization-api)\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "svc_disp = plot_roc_curve(svc, X_test, y_test)\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "svc_disp = plot_roc_curve(svc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "![](images\\auc_graphs.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
