{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel SVM\n",
    "\n",
    "Linear kernel can only be used for Linearly seperable data. In cases of non-linearly seperable data as shown in the RHS image, linear kernel cannot be used for classification.\n",
    "\n",
    "Also, based on the dimension and linearly seperated data we can have different decision boundaries. For example:\n",
    "1. One-dimensional data: Decision boundary will be a dot.\n",
    "\n",
    "2. Two-dimensional data: Decision boundary will be a line\n",
    "3. Three-dimensional data: Decision boundary will be a hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ksvm.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add an extra dimension to space that we are dealing with and we will make the data linearly seperable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping a non-linear  dataset to higher dimensional dataset\n",
    "\n",
    "### Case 1: Single dimension\n",
    "\n",
    "![](ksvm2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set 5 as a constant to be subtracted and all the points will move to the left by 5.\n",
    "\n",
    "![](ksvm3.PNG)\n",
    "\n",
    "Now the next step will be to square `(x-5)` project all these points to y-axis. And we get a parabola.\n",
    "\n",
    "![](ksvm4.PNG)\n",
    "\n",
    "Now we can draw a line to seperate the 2 sets of points.\n",
    "\n",
    "And then what we would do next is project everything back to the original space and we would know how to functionally sperate the green from the red and this is what happens when you map something to a higher dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: 2-D data\n",
    "\n",
    "![](ksvm5.PNG)\n",
    "\n",
    "Then we project the hyperplane back to 2D space to get a circel as the seperator between the 2 classess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ksvm6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems of mapping to higher-dimension is that it can be highly computive-intensive. So this approach isn't exactly the best. We can approach a different approach known as __KERNEL TRICK__. \n",
    "## _KERNEL TRICK_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gaussian RBF Kernel\n",
    "\n",
    "![](ksvm7.PNG)\n",
    "\n",
    "K - Kernel - its the function applied to the 2 vectors.  \n",
    "x - vector\n",
    "l - landmark  \n",
    "i - number of landmarks  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ksvm8.PNG)\n",
    "\n",
    "l - the landmark is in the middle of the 2-D space at the bottom.  \n",
    "the vertical line to the 2-D place is the kernels value when we calculate for every point on the x,l point.  \n",
    "$\\sigma$ - fixed parameter decided earlier\n",
    "\n",
    "The tip of the kernel function is in the middel of (x,l) plane i.e, (0,0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ ||\\overline{x}-\\overline{l}^i||^2 $ shows the distance of the point x to the vertical axis.\n",
    "\n",
    "![](ksvm9.PNG)\n",
    "\n",
    "So closer the point to the vertical line, smaller the value of the fraction => more value for the kernel.  \n",
    "So farther the point to the vertical line, larger the value of the fraction => less value for the kernel.  \n",
    "\n",
    "We can use this kernel function to create the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a way to find the optimal place for the landmark.\n",
    "\n",
    "![](ksvm10.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ksvm11.PNG)\n",
    "\n",
    "So any points outside the circle is given value of zero and points inside the circle is given values greater than zero. \n",
    "\n",
    "Hence we are able to seperate the two classes of red and green.\n",
    "\n",
    "Now as value of sigma will be a constant, its value is also important as they are used to define the circumference of the circle. So by setting up the correct sigma we can setup the correct Kernel function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1: when we increase sigma - Circumfernce of the circle will increase and it will take in more points so chances of wrong points coming into circle increases\n",
    "\n",
    "![](ksvm12.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: when we decrease sigma - Circumfernce of the circle will decrease and it will take in less points so chances of actual points going out of the circle increases\n",
    "\n",
    "![](ksvm13.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So its important to find the right value of sigma to set-up the correct kernel function to seperate the two classes. Otherwise wrong points of a class will be assigned zero or will be put outside the circel or vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So we do the computation in lower dimesnion space. Only the visual representation is done in the higher dimesnional space. We just do if its grater than zero its red class and if less than zero then its green class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combining 2 RBF functions\n",
    "![](ksvm14.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can do all these complex calculations in the lower dimesion space itself we need not go to the higher dimesional sapce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Kernel functions\n",
    "\n",
    "Essence of each function is same you select a landmark and from there depending on the distance to landmark different results will occur\n",
    "\n",
    "For __sigmoid function__ you can observe kernel function is directional so anything to right is high value and to the left is low value and hence can be classified.\n",
    "\n",
    "In __polynomial function__  will dictate based on the polynomial function formed from the data points.\n",
    "\n",
    "![](ksvm15.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google the different kernels in 3-D space to understand the different kernels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
