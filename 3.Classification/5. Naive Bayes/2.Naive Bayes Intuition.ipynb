{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Intuition\n",
    "\n",
    "![](images\\nb1.PNG)\n",
    "\n",
    "## How to apply Naive Bayes to a machine learning algorithm?\n",
    "\n",
    "![](images\\nb7.PNG)\n",
    "\n",
    "Here we are using only 2 variables but in reality we can use many more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of action\n",
    "Probability that someone walks given the new features in our data point which has to be classified\n",
    "\n",
    "### Step 1\n",
    "\n",
    "X - represesnts the feature of the data point to be classified\n",
    "\n",
    "P(Walks|x) - Probability that someone walks given the features X\n",
    "\n",
    "![](images\\nb8.PNG)\n",
    "\n",
    "1. Prior probability:  \n",
    "$$ P(Walks) = \\frac{count(walks)}{count(total)} = \\frac{10}{30}   $$\n",
    "\n",
    "2. Marginal likelihood:\n",
    "\n",
    "To find this we will select a radius and draw a circle around the observation. We have to input this radius to our algo.   Anything inside the circle will be deemed similar to the point that we are trying to classify.   \n",
    "P(X) - tells the likelihood of any random variable falling inside that circle.\n",
    "\n",
    "![](images\\nb11.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. P(X|Walks) - What is the probability that a randomly selected data point from our dataset will be similar to the new data point we have to classifiy? \n",
    "\n",
    "So basically what is the likelihood that a randomly selected data point from the dataset will be from this circle given that that person walks to work? So we will be concerned only with the red dots and ignore the green points.\n",
    "\n",
    "So basically what is the likelihood that a randomly selected red data point from the dataset will fall in this circle and will be having characteristic as that of the unknown point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\nb12.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\nb13.PNG)\n",
    "\n",
    "#### So, 75% is the probability that the person who walks to work given X features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Step 2\n",
    "\n",
    "P(Drives|x) - Probability that someone drives given the features X\n",
    "\n",
    "![](images\\nb9.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prior probability:  \n",
    "20 Green points  \n",
    "30 - Total points  \n",
    "$$ P(Drives) = \\frac{count(Drives)}{count(total)} = \\frac{20}{30}   $$\n",
    "\n",
    "2. Marginal likelihood: What is the likelihood of me selecting a feature that exhibits the same features as the new datapoint?\n",
    "\n",
    "![](images\\nb15.PNG)\n",
    "\n",
    "$$ P(X) = \\frac{4}{30}  $$\n",
    "\n",
    "3. Likelihood P(X|Drives)\n",
    "\n",
    "$$ P(X|Drives) = \\frac{Among-those-in-circle-who-drive}{total-number-of-drivers} = \\frac{1}{20}  $$\n",
    "\n",
    "![](images\\nb14.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Then we compare the two probabilities and based on that we will decide which class to put the new data point.\n",
    "\n",
    "![](images\\nb10.PNG)\n",
    "\n",
    "$$  0.75  >   0.25 $$\n",
    "\n",
    "So we classify the new point as a person who walks to work.\n",
    "\n",
    "So we will classify as red point.\n",
    "\n",
    "***\n",
    "\n",
    "So Naive Bayes is a probabilistic type of classifier and then based on probabilities we are assigning class.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Why Naive bayes is called `Naive`?\n",
    "\n",
    "Coz Bayes Theorem requires some independent assumptions and bayes theorem is the foundation of Naive Bayes ML algorithm. So the algo also relies on these assumptions which at some times is not correct.\n",
    "\n",
    "![](images\\nb7.PNG)\n",
    "\n",
    "As per Bayes theorem, Age and Salary must be independent for applying bayes th, which is not the case fundamentally coz as experience increases salary increases. So features are not completely independent but still on applying it gives good results. So its called Naive as its a naive assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# What is P(X)?\n",
    "\n",
    "P(X) is that likelihood that a randomly selected point from this dataset will exhibit feature similar to dataset that we are about to add/classify. And we assume that everything in that circle will have feature as the datapoint we are going to add/classify.\n",
    "\n",
    "![](images\\nb16.PNG)\n",
    "\n",
    "Same both times when we calcualte - so we can ignore that part and compare just the numerator in both cases to find which one has maximum probability.\n",
    "\n",
    "![](images\\nb17.PNG)\n",
    "\n",
    "$$  0.75  >  0.25 $$\n",
    "\n",
    "So, the probabilities will always add upto 1.\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens when we have more than 2 classes?\n",
    "\n",
    "Same way we have to find the posterior probabilities for all these classes.  Sum of all these probabilities will add upto zero.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
