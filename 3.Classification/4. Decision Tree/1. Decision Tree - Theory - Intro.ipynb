{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "- is a supervised learning model.\n",
    "- Decision support tool that uses a tree-like graph or model of decisions and their possible consequences.\n",
    "- Various variations such as Boosted decision tree, decision forest, etc.\n",
    "- Decision tree and its variations can be used for categorical as well as continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "\n",
    "![](images\\dt1.PNG)\n",
    "\n",
    "We ask questions depending on every parameters eg: whether based on the income levels loan will be approved or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\dt2.PNG)\n",
    "\n",
    "Observe all applications with high income levels were approved. Goal of decision tree in classification is to come up with __pure subset__. __Pure subset is one where you have only one outcome__.\n",
    "\n",
    "And in the case above we have a subset with only one outcome i.e., loan status as Yes. So we do not split this further.\n",
    "\n",
    "Similarly for low income we have only one outcome and we have reached the pure subset and we don't split it further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\dt3.PNG)\n",
    "\n",
    "But for medium income we have 2 loan status levels and is not a pure subset so we have to split it further. So we can split further based on credit score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\dt4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have to split further based on __Employment type__.\n",
    "\n",
    "![](images\\dt5.PNG)\n",
    "\n",
    "So whenever we get a new application we can traverse through these nodes to find the corresponding loan status.\n",
    "\n",
    "As this whole set up looks like an inverted tree hence the name - __decision tree__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminologies used in Decision tree\n",
    "\n",
    "1. __Root node__ - It is the first node here that represents the entire dataset. \n",
    "\n",
    "2. __Splitting__ - It is the process of forming various decision nodes is known as splitting.\n",
    "\n",
    "3. When a subnode splits into further subnodes then its known as __Decision node__.\n",
    "\n",
    "4. And when we do not want to split a decision node further (pure subset) then its known as a __leaf__ or __terminal node__.\n",
    "\n",
    "5. Subsection of this tree which has a decison node or leaf then its known as __branch__ or __subtree__.\n",
    "\n",
    "![](images\\dt6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### ML A-Z\n",
    "\n",
    "![](images\\ml1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images\\ml2.PNG)\n",
    "\n",
    "Split is done by decision tree algorithm such that we can maximize the number of categories in each of these splits.\n",
    "\n",
    "Eg:\n",
    "- Split 1 maximizes the number of red split in bottom i.e., x2 < 60\n",
    "- Split 2 maximizes the number of red andd green splits at x1 = 50\n",
    "\n",
    "In reality, in background split is trying to minimize entropy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
