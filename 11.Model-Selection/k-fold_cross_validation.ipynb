{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will do 2 things:\n",
    "1. Evaluating our model performance\n",
    "2. Improving our model performance\n",
    "\n",
    "Improving the model performance can be done with technique called __Model Selection__ that consists of choosing the best parameters of your machine learning models. Every time we built a machine learning model we have two types of parameters:\n",
    "- Parameters that were changed and optimal values for them was found by running the model\n",
    "- Parameters that we choose ourselves.\n",
    "\n",
    "***\n",
    "\n",
    "__Reference:__\n",
    "[What is the Difference Between a Parameter and a Hyperparameter?](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/)\n",
    "\n",
    "A __model parameter__ is a configuration variable that is internal to the model and whose value can be estimated from data. They are often not set manually by the practitioner. Some examples of model parameters include:\n",
    "\n",
    "- The weights in an artificial neural network.\n",
    "- The support vectors in a support vector machine.\n",
    "- The coefficients in a linear regression or logistic regression.\n",
    "\n",
    "A __model hyperparameter__ is a configuration that is external to the model and whose value cannot be estimated from data. They are often used in processes to help estimate model parameters. They are often specified by the practitioner. They can often be set using heuristics. They are often tuned for a given predictive modeling problem.\n",
    "\n",
    "We cannot know the best value for a model hyperparameter on a given problem. We may use rules of thumb, copy values used on other problems, or search for the best value by trial and error.\n",
    "\n",
    "When a machine learning algorithm is tuned for a specific problem, such as when you are using a grid search or a random search, then you are tuning the hyperparameters of the model or order to discover the parameters of the model that result in the most skillful predictions.\n",
    "\n",
    "Some examples of model hyperparameters include:\n",
    "- The learning rate for training a neural network.\n",
    "- The C and sigma hyperparameters for support vector machines.\n",
    "- The k in k-nearest neighbors.\n",
    "\n",
    " A good rule of thumb to overcome this confusion is as follows:\n",
    "> If you have to specify a model parameter manually then\n",
    "it is probably a model hyperparameter.\n",
    "\n",
    "***\n",
    "\n",
    "Grid Search helps us choose the model hyperparameters.\n",
    "\n",
    "Just by checking accuracy of our model on one test data we cannot be sure of the models performance and accuracy. Also the variance problem.\n",
    "\n",
    "And so there is a technique called __k-Fold cross validation__ that improves this a lot becasue that will fix this variance problem.\n",
    "\n",
    "__k-Fold cross validation__ will split the training set into 10 folds (wken k=10) and we train our model on 9 folds and test on the last remaing fold. So we can get 10 combinations of data and in each combination we will have 9 folds to train the model and 1 to test it.\n",
    "\n",
    "![](k1.png)\n",
    "\n",
    "Then we can take average of the accuracy of the 10 evaluations and also compute the standard deviation to look at the variance.\n",
    "\n",
    "And we can know in which of the four category we will be:\n",
    "![](k2.png)\n",
    "\n",
    "So our model will be more relevant.\n",
    "\n",
    "The most relevant position for the k-fold cross validation is right after we have build the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Fold Cross Validation\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sklearn k-Fold Cross Validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "\n",
    "__cv__ parameter is the number of folds that we want to split the training set into.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8       , 0.96666667, 0.8       , 0.96666667, 0.86666667,\n",
       "       0.86666667, 0.9       , 0.93333333, 1.        , 0.93333333])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "# accuracies is a vector that will get the 10 accuracies computed through k-fold cross validation\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033333333333333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06574360974438671"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std() # we get 6% std deviation - low variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
