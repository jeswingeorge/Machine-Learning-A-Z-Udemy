{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression\n",
    "\n",
    "Here \n",
    "\n",
    "![](images/10_1.PNG)\n",
    "\n",
    "***\n",
    "\n",
    "We try to create a linear regression model or try to fit a linear model on a given dataset of weight vs sizes.\n",
    "\n",
    "\n",
    "![](images/10_b.PNG)\n",
    "\n",
    "![](images/10_c.png)\n",
    "\n",
    "When we have a lot of measurements we can be fairly confident that the Least squares line accurately reflects the relationship between Size and weight.\n",
    "\n",
    "But what if the dataset has very few points.\n",
    "\n",
    "![](images/10_d.PNG)\n",
    "\n",
    "\n",
    "The sum of the squared residuals for just the __Two Red Points__, the __Training Data__ is small(in this case it is 0) but the sum of the squared residuals for the __Green Points__, the Testing Data is large and this means that the fitted line has high variance.\n",
    "\n",
    "> In ML lingo, we can say that the fitted line is overfitted to the training data.\n",
    "\n",
    "![](images/10_e.PNG)\n",
    "\n",
    "![](images/10_f.PNG)\n",
    "\n",
    "![](images/10_g.PNG)\n",
    "\n",
    "In other words, by starting with a slightly wrong fit, __Ridge Regression__ can provide better long term predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Ridge regression in detail\n",
    "\n",
    "![](images/10_h.PNG)\n",
    "\n",
    "\n",
    "![](images/10_i.PNG)\n",
    "\n",
    "$\\lambda*slope^{2}$ adds a penalty to the traditional __least squares__ method and $\\lambda$ determines how severe that penalty is.\n",
    "\n",
    "![](images/10_j.PNG)\n",
    "\n",
    "![](images/10_k.PNG)\n",
    "\n",
    "Without the small amount of __Bias__ that the penalty creates, the __Least squares fit__ has a large amount of variance. In contrast, the Ridge regression line which has the small amount of __Bias__ due to the penalty has less __Variance__. \n",
    "\n",
    "## Effect of the ridge regression penalty on the fitting line\n",
    "\n",
    "\n",
    "#### Case 1: If the fitting lines slope=1\n",
    "\n",
    "![](images/10_l.PNG)\n",
    "\n",
    "#### Case 2: If the slope is steep\n",
    "\n",
    "![](images/10_m.PNG)\n",
    "\n",
    "#### Case 3: If the slope is small\n",
    "\n",
    "![](images/10_n.PNG)\n",
    "\n",
    "Now lets go back to the __Least Squares__ and __Ridge regression__ lines fit to the two data points.\n",
    "\n",
    "![](images/10_o.PNG)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## Lambda $\\lambda$\n",
    "\n",
    "- $\\lambda$ can take any value from 0 to +ve infinity [0,$\\propto$).\n",
    "- when $\\lambda = 0$ then Ridge regression will only minimise the SSR as the penalty parameter will be zero and ridge regression line will be the same as the least squares fit line.\n",
    "- As we increase $\\lambda$ the slope will go on decreasing and the larger we make lambda the slope get aymptotically close to __0__. So the larger lambda gets our prediction for size becomes less and less sensitive to weight (i.e., x-value).\n",
    "\n",
    "#### So how do we decide to take which value of $\\lambda$?\n",
    "\n",
    "We just try a bunch of values for $\\lambda$ and use __cross validation__, typically __10-fold cross validation__ to determine which one results in the lowest __variance__.\n",
    "\n",
    "***\n",
    "\n",
    "Ridge regression also works when we use a discrete variable like __Normal diet vs high fat diet__ to predict __size__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T10:20:07.523364Z",
     "start_time": "2020-04-14T10:20:07.507370Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5:03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
