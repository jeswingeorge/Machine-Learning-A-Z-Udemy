{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York', 'California', 'Florida'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 'New York'],\n",
       "       [162597.7, 151377.59, 443898.53, 'California'],\n",
       "       [153441.51, 101145.55, 407934.54, 'Florida'],\n",
       "       [144372.41, 118671.85, 383199.62, 'New York'],\n",
       "       [142107.34, 91391.77, 366168.42, 'Florida'],\n",
       "       [131876.9, 99814.71, 362861.36, 'New York'],\n",
       "       [134615.46, 147198.87, 127716.82, 'California'],\n",
       "       [130298.13, 145530.06, 323876.68, 'Florida'],\n",
       "       [120542.52, 148718.95, 311613.29, 'New York'],\n",
       "       [123334.88, 108679.17, 304981.62, 'California'],\n",
       "       [101913.08, 110594.11, 229160.95, 'Florida'],\n",
       "       [100671.96, 91790.61, 249744.55, 'California'],\n",
       "       [93863.75, 127320.38, 249839.44, 'Florida'],\n",
       "       [91992.39, 135495.07, 252664.93, 'California'],\n",
       "       [119943.24, 156547.42, 256512.92, 'Florida'],\n",
       "       [114523.61, 122616.84, 261776.23, 'New York'],\n",
       "       [78013.11, 121597.55, 264346.06, 'California'],\n",
       "       [94657.16, 145077.58, 282574.31, 'New York'],\n",
       "       [91749.16, 114175.79, 294919.57, 'Florida'],\n",
       "       [86419.7, 153514.11, 0.0, 'New York'],\n",
       "       [76253.86, 113867.3, 298664.47, 'California'],\n",
       "       [78389.47, 153773.43, 299737.29, 'New York'],\n",
       "       [73994.56, 122782.75, 303319.26, 'Florida'],\n",
       "       [67532.53, 105751.03, 304768.73, 'Florida'],\n",
       "       [77044.01, 99281.34, 140574.81, 'New York'],\n",
       "       [64664.71, 139553.16, 137962.62, 'California'],\n",
       "       [75328.87, 144135.98, 134050.07, 'Florida'],\n",
       "       [72107.6, 127864.55, 353183.81, 'New York'],\n",
       "       [66051.52, 182645.56, 118148.2, 'Florida'],\n",
       "       [65605.48, 153032.06, 107138.38, 'New York'],\n",
       "       [61994.48, 115641.28, 91131.24, 'Florida'],\n",
       "       [61136.38, 152701.92, 88218.23, 'New York'],\n",
       "       [63408.86, 129219.61, 46085.25, 'California'],\n",
       "       [55493.95, 103057.49, 214634.81, 'Florida'],\n",
       "       [46426.07, 157693.92, 210797.67, 'California'],\n",
       "       [46014.02, 85047.44, 205517.64, 'New York'],\n",
       "       [28663.76, 127056.21, 201126.82, 'Florida'],\n",
       "       [44069.95, 51283.14, 197029.42, 'California'],\n",
       "       [20229.59, 65947.93, 185265.1, 'New York'],\n",
       "       [38558.51, 82982.09, 174999.3, 'California'],\n",
       "       [28754.33, 118546.05, 172795.67, 'California'],\n",
       "       [27892.92, 84710.77, 164470.71, 'Florida'],\n",
       "       [23640.93, 96189.63, 148001.11, 'California'],\n",
       "       [15505.73, 127382.3, 35534.17, 'New York'],\n",
       "       [22177.74, 154806.14, 28334.72, 'California'],\n",
       "       [1000.23, 124153.04, 1903.93, 'New York'],\n",
       "       [1315.46, 115816.21, 297114.46, 'Florida'],\n",
       "       [0.0, 135426.92, 0.0, 'California'],\n",
       "       [542.05, 51743.15, 0.0, 'New York'],\n",
       "       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94, 156991.12,\n",
       "       156122.51, 155752.6 , 152211.77, 149759.96, 146121.95, 144259.4 ,\n",
       "       141585.52, 134307.35, 132602.65, 129917.04, 126992.93, 125370.37,\n",
       "       124266.9 , 122776.86, 118474.03, 111313.02, 110352.25, 108733.99,\n",
       "       108552.04, 107404.34, 105733.54, 105008.31, 103282.38, 101004.64,\n",
       "        99937.59,  97483.56,  97427.84,  96778.92,  96712.8 ,  96479.51,\n",
       "        90708.19,  89949.14,  81229.06,  81005.76,  78239.91,  77798.83,\n",
       "        71498.49,  69758.98,  65200.33,  64926.08,  49490.75,  42559.73,\n",
       "        35673.41,  14681.4 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the categorical column in X to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colT = ColumnTransformer([('colt', OneHotEncoder(categories = [['New York', 'California', 'Florida']]), [3])], \n",
    "                         remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 165349.2, 136897.8, 471784.1],\n",
       "       [0.0, 1.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [0.0, 0.0, 1.0, 153441.51, 101145.55, 407934.54],\n",
       "       [1.0, 0.0, 0.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 0.0, 1.0, 142107.34, 91391.77, 366168.42],\n",
       "       [1.0, 0.0, 0.0, 131876.9, 99814.71, 362861.36],\n",
       "       [0.0, 1.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 0.0, 1.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1.0, 0.0, 0.0, 120542.52, 148718.95, 311613.29],\n",
       "       [0.0, 1.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 0.0, 1.0, 101913.08, 110594.11, 229160.95],\n",
       "       [0.0, 1.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [0.0, 0.0, 1.0, 93863.75, 127320.38, 249839.44],\n",
       "       [0.0, 1.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 0.0, 1.0, 119943.24, 156547.42, 256512.92],\n",
       "       [1.0, 0.0, 0.0, 114523.61, 122616.84, 261776.23],\n",
       "       [0.0, 1.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1.0, 0.0, 0.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 0.0, 1.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1.0, 0.0, 0.0, 86419.7, 153514.11, 0.0],\n",
       "       [0.0, 1.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1.0, 0.0, 0.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 0.0, 1.0, 73994.56, 122782.75, 303319.26],\n",
       "       [0.0, 0.0, 1.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1.0, 0.0, 0.0, 77044.01, 99281.34, 140574.81],\n",
       "       [0.0, 1.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 0.0, 1.0, 75328.87, 144135.98, 134050.07],\n",
       "       [1.0, 0.0, 0.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 0.0, 1.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1.0, 0.0, 0.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 0.0, 1.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1.0, 0.0, 0.0, 61136.38, 152701.92, 88218.23],\n",
       "       [0.0, 1.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [0.0, 0.0, 1.0, 55493.95, 103057.49, 214634.81],\n",
       "       [0.0, 1.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1.0, 0.0, 0.0, 46014.02, 85047.44, 205517.64],\n",
       "       [0.0, 0.0, 1.0, 28663.76, 127056.21, 201126.82],\n",
       "       [0.0, 1.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [1.0, 0.0, 0.0, 20229.59, 65947.93, 185265.1],\n",
       "       [0.0, 1.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [0.0, 1.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 0.0, 1.0, 27892.92, 84710.77, 164470.71],\n",
       "       [0.0, 1.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1.0, 0.0, 0.0, 15505.73, 127382.3, 35534.17],\n",
       "       [0.0, 1.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1.0, 0.0, 0.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 0.0, 1.0, 1315.46, 115816.21, 297114.46],\n",
       "       [0.0, 1.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1.0, 0.0, 0.0, 542.05, 51743.15, 0.0],\n",
       "       [0.0, 1.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = colT.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we need to avoid the dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [0.0, 1.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 0.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 1.0, 142107.34, 91391.77, 366168.42],\n",
       "       [0.0, 0.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 1.0, 130298.13, 145530.06, 323876.68],\n",
       "       [0.0, 0.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 1.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [0.0, 1.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 1.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 0.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 0.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 1.0, 91749.16, 114175.79, 294919.57],\n",
       "       [0.0, 0.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 0.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 1.0, 73994.56, 122782.75, 303319.26],\n",
       "       [0.0, 1.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 0.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 1.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 0.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 1.0, 66051.52, 182645.56, 118148.2],\n",
       "       [0.0, 0.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 1.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 0.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [0.0, 1.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [0.0, 0.0, 46014.02, 85047.44, 205517.64],\n",
       "       [0.0, 1.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 0.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 1.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [0.0, 0.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [0.0, 0.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 1.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [0.0, 0.0, 542.05, 51743.15, 0.0],\n",
       "       [1.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[:,1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need not use feature scaling for multiple linear rgeression because the library will take of that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting multiple linear regression to the training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "      <th>residuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103015.201598</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>-267.178402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132582.277608</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>-11677.122392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132447.738452</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>-13674.211548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71976.098513</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>-5822.731487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178537.482211</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>-12512.907789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>116161.242302</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>11152.932302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67851.692097</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>-13377.367903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>98791.733747</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>1308.173747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>113969.435330</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>3617.185330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167921.065696</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>1733.125696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_pred     y_test     residuals\n",
       "0  103015.201598  103282.38   -267.178402\n",
       "1  132582.277608  144259.40 -11677.122392\n",
       "2  132447.738452  146121.95 -13674.211548\n",
       "3   71976.098513   77798.83  -5822.731487\n",
       "4  178537.482211  191050.39 -12512.907789\n",
       "5  116161.242302  105008.31  11152.932302\n",
       "6   67851.692097   81229.06 -13377.367903\n",
       "7   98791.733747   97483.56   1308.173747\n",
       "8  113969.435330  110352.25   3617.185330\n",
       "9  167921.065696  166187.94   1733.125696"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for comaring\n",
    "df = pd.DataFrame()\n",
    "df['y_pred'] = y_pred\n",
    "df['y_test'] = y_test\n",
    "df['residuals'] = y_pred - y_test\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to improve the model performance we need to consider only those independant variables that have a good impact on the dependant vriable i.e., those variables which are highly statistically significant and have a good effect on the dependant variable. The coefficeints can be positive or negative. Doing this using __Backward eleimination__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](mutli_eqn.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward elimination will add a column of 1's in the columns of independant features.\n",
    "\n",
    "From the eqn above we see that there is a variable $b_0$ which is not associated with any independant variable x. So we can associate a variable $x_0 = 1$ with the constant $b_0$. \n",
    "\n",
    "Also in The matrix of features X there is no column with value 1 i.e, $b_0$ so we need to add the column of ones in X.\n",
    "\n",
    "Reference:\n",
    "\n",
    "- [Numpy ones](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html)\n",
    "- [Numpy append](https://docs.scipy.org/doc/numpy/reference/generated/numpy.append.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if astype(int) is not used we will get a datatype error\n",
    "X = np.append(arr = np.ones((50,1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0.0, 0.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1, 1.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1, 0.0, 1.0, 153441.51, 101145.55, 407934.54],\n",
       "       [1, 0.0, 0.0, 144372.41, 118671.85, 383199.62],\n",
       "       [1, 0.0, 1.0, 142107.34, 91391.77, 366168.42],\n",
       "       [1, 0.0, 0.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1, 1.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1, 0.0, 1.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1, 0.0, 0.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1, 1.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1, 0.0, 1.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1, 1.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1, 0.0, 1.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1, 1.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1, 0.0, 1.0, 119943.24, 156547.42, 256512.92],\n",
       "       [1, 0.0, 0.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1, 1.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1, 0.0, 0.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1, 0.0, 1.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1, 0.0, 0.0, 86419.7, 153514.11, 0.0],\n",
       "       [1, 1.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1, 0.0, 0.0, 78389.47, 153773.43, 299737.29],\n",
       "       [1, 0.0, 1.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1, 0.0, 1.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1, 0.0, 0.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1, 1.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1, 0.0, 1.0, 75328.87, 144135.98, 134050.07],\n",
       "       [1, 0.0, 0.0, 72107.6, 127864.55, 353183.81],\n",
       "       [1, 0.0, 1.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1, 0.0, 0.0, 65605.48, 153032.06, 107138.38],\n",
       "       [1, 0.0, 1.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1, 0.0, 0.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1, 1.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1, 0.0, 1.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1, 1.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1, 0.0, 0.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1, 0.0, 1.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1, 1.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [1, 0.0, 0.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1, 1.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1, 1.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1, 0.0, 1.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1, 1.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1, 0.0, 0.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1, 1.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1, 0.0, 0.0, 1000.23, 124153.04, 1903.93],\n",
       "       [1, 0.0, 1.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1, 1.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1, 0.0, 0.0, 542.05, 51743.15, 0.0],\n",
       "       [1, 1.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_opt will have the matrix of independant team of variables that are statistically significant\n",
    "# initialise it with all the independant features first then as backward elimination continues \n",
    "# we will remove the significally insignificant variable\n",
    "X_opt = np.array(X[:,[0,1,2,3,4,5]], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](BE.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward elimination steps\n",
    "\n",
    "__Step 1__: Use significance level of 5% or 0.05.\n",
    "\n",
    "__Step 2__: We will use regressor from the statsmodels library (as opposed to linear model library) and the new class is OLS (ordinary least square class)\n",
    "\n",
    "Reference:\n",
    "\n",
    "- [Implementing ordinary least squares (OLS) using Statsmodels in Python](https://heartbeat.fritz.ai/implementing-ordinary-least-squares-ols-using-statsmodels-in-python-b1f4dee09419)\n",
    "\n",
    "- [statsmodels.regression.linear_model.OLS](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html)\n",
    "\n",
    "- [Errors and the solutions obtained when runnng the codes](https://stackoverflow.com/questions/56449787/attributeerror-module-statsmodels-formula-api-has-no-attribute-ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the otimal model using backward elimination\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3__: Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to find the p-value we will use the summary function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:13:12</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.008e+04</td> <td> 6952.587</td> <td>    7.204</td> <td> 0.000</td> <td> 3.61e+04</td> <td> 6.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   41.8870</td> <td> 3256.039</td> <td>    0.013</td> <td> 0.990</td> <td>-6520.229</td> <td> 6604.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  240.6758</td> <td> 3338.857</td> <td>    0.072</td> <td> 0.943</td> <td>-6488.349</td> <td> 6969.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.47e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Fri, 20 Mar 2020   Prob (F-statistic):           1.34e-27\n",
       "Time:                        11:13:12   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.008e+04   6952.587      7.204      0.000    3.61e+04    6.41e+04\n",
       "x1            41.8870   3256.039      0.013      0.990   -6520.229    6604.003\n",
       "x2           240.6758   3338.857      0.072      0.943   -6488.349    6969.701\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.47e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.47e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above the lower the p-value is the more significant will be your independant variable is going to be with respect to your dependant variable. From above \n",
    "\n",
    "__Step 4__:\n",
    "\n",
    "const - $x_0$  and other independant variables x1, x2, x3, x4 and x5 => among these we have to look for the highest p-value in $P>|t|$ and it is x1 with 0.99 which is way above significance level of 0.05. So we need to remove that variable x1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:31:04</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Fri, 20 Mar 2020   Prob (F-statistic):           8.49e-29\n",
       "Time:                        11:31:04   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = np.array(X[:,[0,2,3,4,5]], dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here x1 has maximum p-value and is greater than 0.5 so remove the corresponding column index from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:33:28</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Fri, 20 Mar 2020   Prob (F-statistic):           4.53e-30\n",
       "Time:                        11:33:28   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = np.array(X[:,[0,3,4,5]], dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here x2 has the maximum value of p with 0.602 and it is greater than 0.05. So remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:37:39</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Fri, 20 Mar 2020   Prob (F-statistic):           2.16e-31\n",
       "Time:                        11:37:39   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = np.array(X[:,[0,3,5]], dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here x2 has the maximum value of p with 0.06 and it is greater than 0.05. So remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:38:38</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Fri, 20 Mar 2020   Prob (F-statistic):           3.50e-32\n",
       "Time:                        11:38:38   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = np.array(X[:,[0,3]], dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.78269692e-24, 3.50032224e-32])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "[Numpy delete](https://docs.scipy.org/doc/numpy/reference/generated/numpy.delete.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Elimination with p-values only:\n",
    "\n",
    "```\n",
    "import statsmodels.api as sm\n",
    "def backwardElimination(x, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination with p-values and Adjusted R Squared:\n",
    "\n",
    "```\n",
    "def backwardElimination(x, SL):\n",
    "    numVars = len(x[0])\n",
    "    temp = np.zeros((50,6)).astype(int)\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
    "        if maxVar > SL:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    temp[:,j] = x[:, j]\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    tmp_regressor = sm.OLS(y, x).fit()\n",
    "                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
    "                    if (adjR_before >= adjR_after):\n",
    "                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "                        print (regressor_OLS.summary())\n",
    "                        return x_rollback\n",
    "                    else:\n",
    "                        continue\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
