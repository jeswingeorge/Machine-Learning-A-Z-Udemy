# [Udemy Machine Learning A-Z course](https://www.udemy.com/machinelearning/)
[Download datasets for this course from website](www.superdatascience.com/pages/machine-learning)

This repository contains notes and assignments of this course.


## 1. Data pre-processing
- [Data-preprocessing - Using sklearn and tutorials](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/1.Data%20Preprocessing/Data-preprocessing%20-%20Using%20sklearn%20and%20tutorials.ipynb)  
  Topics covered: Missing data, Categorical data, Feature scaling, Splitting data into train and test set

- [Using sklearn's ColumnTransformer for Numerical and Categorical Data in Python](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/1.Data%20Preprocessing/3.Use%20ColumnTransformer%20in%20SciKit%20instead%20of%20LabelEncoding%20and%20OneHotEncoding%20in%20ML.ipynb)  
  Topics covered: Using Column Transformer function on ultiple libraries

- [Data-preprocessing - Using Pandas and my trials](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/1.Data%20Preprocessing/Data-preprocessing%20-%20Using%20Pandas%20and%20my%20trials.ipynb)  
  Topics covered: Using pandas for Missing data, Categorical data


## 2. Regression
- [Regression Introduction](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/2.Regression/3.Intro/Regression%20Intro.ipynb)  
  Topics covered: Regression definition and types
- [Simple Linear Regression](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/2.Regression/4.%20Simple%20Linear%20Regression/simple_linear_regression.ipynb)  
  Topics covered: Simple linear regression Introduction
- [Simple Linear Regression - Notes-2](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/2.Regression/4.%20Simple%20Linear%20Regression/Simple_Linear_reg-Notes-2.ipynb)  
 Topics covered: Assumptions of Linear Regression and their validation, Coefficient of determination $R^2$ and adjusted $R^2$.
- [Multiple Linear Regression-1](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/2.Regression/5.Multiple%20Linear%20Regression/2.%20Multiple%20regression.ipynb)  
	Topics covered: Creating dummy variables, Dummy Variable Trap, P-value in regression analysis and coefficients
- [Multiple Linear Regression-2: 5 methods of building a model](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/2.Regression/5.Multiple%20Linear%20Regression/1.%20Building%20a%20model%20%28step%20by%20step%29.ipynb)  
 Topics covered: All-in, Backward Elimination, Forward selection, Bidirectional Elimination, Score comparison/All possible models
 - [Polynomial regression](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/2.Regression/6.%20Polynomial%20Regression/polynomial_regression.ipynb)  
  Topics covered - why polynomial regression is called linear
- [Multiple linear regression implementation with backward elimination](https://nbviewer.jupyter.org/github/jeswingeorge/Machine-Learning-A-Z-Udemy/blob/master/2.Regression/5.Multiple%20Linear%20Regression/3.multi_linear_reg_backward_elimination.ipynb)
- [Implementing Polynomial regression in Python]()

 

 